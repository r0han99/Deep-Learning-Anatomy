,desc,project_name,framework,prediction_type,network_type,architecture,layers,hidden_units,activations,epochs,metrics,train_accuracy,test_accuracy,classification_report,elapsed,summary,ipynb,plots
0,"The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.",MNIST,Pytorch,Classification,Convolutional Neural Network,"convolutional(
  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)",6,,"['relu','softmax']",5,Accuracy,96.58,98.72,"              precision    recall  f1-score   support

           0       0.99      0.99      0.99       980
           1       1.00      0.99      0.99      1135
           2       0.99      0.99      0.99      1032
           3       0.99      0.99      0.99      1010
           4       0.99      0.99      0.99       982
           5       0.98      0.99      0.98       892
           6       0.99      0.98      0.99       958
           7       0.99      0.99      0.99      1028
           8       0.97      0.99      0.98       974
           9       0.99      0.98      0.98      1009

    accuracy                           0.99     10000
   macro avg       0.99      0.99      0.99     10000
weighted avg       0.99      0.99      0.99     10000
",2.48 Min,"Considering the Visualisations concerning train-cycle and test-cycle, after the 3rd epoch the training error starts increasing ever-so slightly which determines that after 3rd epoch with this network architecture the model overfits the data. This is evident in the difference between train-accuracy and test-accuracy. But this problem is not prominent to work on reducing that difference, if we are supposed to reduce that error we can try using dropout layers and early-stopping techniques",./Projects/MNIST/Pytorch/MNIST-Pytorch.pdf,./Projects/MNIST/Pytorch/Plots
