{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore','DeprecatedWarnings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train,y_train), ( x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'label 7')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPi0lEQVR4nO3dbYyVdXrH8d9P65rWtfWBCVJFZrsiypqUNRNsI1E3tsaHF+jamsVoqGsY2oq6zbappSYaXrSuFRXTZi1WI8L6GJeoLbqoaaSbrhsHpYJiK0tQBlGG4CrICwpefXFutuM45z7DeWau7yc5mTP3dT9c3Otv7zPnf+7zd0QIwPh3RKcbANAehB1IgrADSRB2IAnCDiRB2IEkCPs4Y3uL7T8Y47ph+7Q6j1P3tugMwo6ms/2W7T3DHvttP9fpvrL7tU43gPEnIr5x8LltS9os6anOdQSJK/u4Znum7Z/Z/qXt7bb/0fZXRqx2qe3Ntnfa/gfbRwzb/ru2N9r+2PZPbE+po43zJE2Q9HQj/xY0jrCPbwck/YUqYft9SRdK+vMR61whqU/S2ZJmS/quJNmeLWmhpG9L6pH0H5Ieq6OHuZKejojP6tgWTUTYx7GIWBsRr0bE/ojYIumfJZ0/YrUfRMSuiHhf0r2S5hTL/1TS30fExojYL+nvJM04lKu77d+Q9EeSHm7sX4JmIOzjmO3Tbf+r7Q9tf6pKYCeMWG3rsOfvSfrt4vkUSUuKPwF+KWmXJEs6+RBa+Hax3Sv19I/mIuzj2w8lvSNpakT8piovyz1incnDnp8q6YPi+VZJ8yPiuGGPX4+I/zyE48+V9Ehwa2VXIOzj27GSPpW0x/YZkv5slHX+yvbxtidLulnSE8Xy+yX9je1vSJLt37L9x2M9sO1TJH1L0rJG/gFoHsI+vv2lpKsl7Zb0gP4/yMM9I2mtpHWS/k3Sg5IUESsl/UDS48WfABskXXIIx75W0s8i4hf1No/mMq+wgBy4sgNJEHYgCcIOJEHYgSTaeiPMhAkTore3t52HBFLZsmWLdu7cOfKzFJIaDLvtiyUtkXSkpH+JiDvK1u/t7dXAwEAjhwRQoq+vr2qt7pfxto+U9E+qjL1OlzTH9vR69wegtRr5m32mpE0RsTki9kl6XJW7pgB0oUbCfrK+eBPFoEa5ScJ2v+0B2wNDQ0MNHA5AI1r+bnxELI2Ivojo6+npafXhAFTRSNi36Yt3TJ1SLAPQhRoJ+2uSptr+WvFVR9+R9Gxz2gLQbHUPvUXEftsLJP1ElaG3hyLiraZ1BqCpGhpnj4hVklY1qRcALcTHZYEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJNDRls+0tknZLOiBpf0T0NaMpAM3XUNgL34qInU3YD4AW4mU8kESjYQ9Jq22vtd0/2gq2+20P2B4YGhpq8HAA6tVo2GdFxNmSLpF0g+3zRq4QEUsjoi8i+np6eho8HIB6NRT2iNhW/NwhaaWkmc1oCkDz1R1228fYPvbgc0kXSdrQrMYANFcj78ZPlLTS9sH9PBoRLzSlKwBNV3fYI2KzpN9tYi8AWoihNyAJwg4kQdiBJAg7kARhB5Joxo0wSGzx4sWl9X379lWtbdy4sXTbFStW1NXTQWeccUbV2ttvv93Qvg9HXNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2ce5V155pbS+fv360vqaNWtK6ytXriytf/7556X1MsXt03XbtGlT1dqZZ55Zum2tzwAcjriyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLO3wfbt20vrc+bMKa1v3ry57mN/8sknpfU9e/aU1iOitN7XVz5x79q1a0vrrXTgwIGqtb1797axk+7AlR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcvQleeuml0vq8efNK6++//34z22mqWvd1T5gwobS+c+fOqrUPPvigdNvrrruutL5169bSepnp06fXve3hquaV3fZDtnfY3jBs2Qm2X7T9bvHz+Na2CaBRY3kZ/7Cki0csu0XSyxExVdLLxe8AuljNsEfEGkm7RiyeLWlZ8XyZpMub2xaAZqv3DbqJEXHwA98fSppYbUXb/bYHbA8MDQ3VeTgAjWr43fio3ClR9W6JiFgaEX0R0dfT09Po4QDUqd6wf2R7kiQVP3c0ryUArVBv2J+VNLd4PlfSM81pB0Cr1Bxnt/2YpAskTbA9KOk2SXdIetL29ZLek3RVK5vsdnfeeWdpvdXj6EcffXTVWq3ezjnnnNL6tGnT6urpoBNPPLFqbcmSJaXbNjKOLkm9vb1Va8uXL29o34ejmmGPiGrfrHBhk3sB0EJ8XBZIgrADSRB2IAnCDiRB2IEkuMV1jFavXl219uqrr7b02KeeemppvWwYadasWc1up2kGBwdbuv/Zs2dXrdW6NXc84soOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzj5Gixcvrlr77LPPGtr3ueeeW1q/7bbbSuudHEv/+OOPS+vPP/981dqaNWsaOnat83bZZZc1tP/xhis7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPsY9ff3V63VmtbquOOOK60/+uijpfWTTjqptN5J999/f2n91ltvrXvfZ511Vmn9ySefLK1383nrBK7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+xjdOWVV9ZVO9w999xzpfVFixbVve+jjjqqtD5//vzSOuPoh6bmld32Q7Z32N4wbNnttrfZXlc8Lm1tmwAaNZaX8Q9LuniU5fdExIzisaq5bQFotpphj4g1kna1oRcALdTIG3QLbL9ZvMw/vtpKtvttD9geqPUZcgCtU2/Yfyjp65JmSNouqeq3MUbE0ojoi4i+np6eOg8HoFF1hT0iPoqIAxHxuaQHJM1sblsAmq2usNueNOzXKyRtqLYugO5Qc5zd9mOSLpA0wfagpNskXWB7hqSQtEVS+YAoDltlc5xLku26933fffeV1su+QwCHrmbYI2LOKIsfbEEvAFqIj8sCSRB2IAnCDiRB2IEkCDuQBLe4Jrdw4cLSekS07Njnn39+y/aNL+PKDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+zu3bt6+0/sYbb5TWa93CWqu+ZMmSqrWpU6eWbovm4soOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzj4O7N27t2ptxYoVpduuXr26oWNfffXVpfVrrrmmau2II7jWtBNnG0iCsANJEHYgCcIOJEHYgSQIO5AEYQeSGMuUzZMlPSJpoipTNC+NiCW2T5D0hKReVaZtvioiPm5dq3nt3r27tD5v3ryqtaeeeqqhY997772l9QULFpTWGUvvHmP5X2K/pO9HxHRJvyfpBtvTJd0i6eWImCrp5eJ3AF2qZtgjYntEvF483y1po6STJc2WtKxYbZmky1vUI4AmOKTXWLZ7JX1T0s8lTYyI7UXpQ1Ve5gPoUmMOu+2vSnpa0vci4tPhtahMCDbqpGC2+20P2B4YGhpqqFkA9RtT2G0fpUrQfxQRPy4Wf2R7UlGfJGnHaNtGxNKI6IuIvp6enmb0DKAONcPuyteHPihpY0TcPaz0rKS5xfO5kp5pfnsAmmUst7ieK+laSettryuWLZR0h6QnbV8v6T1JV7WkQ2hwcLC03sjw2mmnnVZav+mmm+reN7pLzbBHxE8lVfty8Aub2w6AVuETD0AShB1IgrADSRB2IAnCDiRB2IEk+CrpLvDOO++U1u++++7SepnTTz+9tP7CCy/UvW8cXriyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLN3gUWLFpXWn3jiibr3feONN5bWp0yZUve+cXjhyg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDO3gYbNmwordeakrmW+fPnV61deCHf9o0KruxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kETNcXbbkyU9ImmipJC0NCKW2L5d0jxJQ8WqCyNiVasaPZwtX768tL5qVflpq3XP+c0331y1Nm3atNJtkcdYPlSzX9L3I+J128dKWmv7xaJ2T0Tc1br2ADRLzbBHxHZJ24vnu21vlHRyqxsD0FyH9De77V5J35T082LRAttv2n7I9vFVtum3PWB7YGhoaLRVALTBmMNu+6uSnpb0vYj4VNIPJX1d0gxVrvyLR9suIpZGRF9E9PX09DTeMYC6jCnsto9SJeg/iogfS1JEfBQRByLic0kPSJrZujYBNKpm2G1b0oOSNkbE3cOWTxq22hWSym/tAtBRY3k3/lxJ10pab3tdsWyhpDm2Z6gyHLdFUvX7LJO76KKLSut33VU+oHHPPfeU1hlew1iM5d34n0ryKCXG1IHDCJ+gA5Ig7EAShB1IgrADSRB2IAnCDiTBV0m3Qa2vcz5w4ECbOkFmXNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAlHRPsOZg9Jem/YogmSdratgUPTrb11a18SvdWrmb1NiYhRv/+trWH/0sHtgYjo61gDJbq1t27tS6K3erWrN17GA0kQdiCJTod9aYePX6Zbe+vWviR6q1dbeuvo3+wA2qfTV3YAbULYgSQ6EnbbF9v+b9ubbN/SiR6qsb3F9nrb62wPdLiXh2zvsL1h2LITbL9o+93i56hz7HWot9ttbyvO3Trbl3aot8m2/93227bfsn1zsbyj566kr7act7b/zW77SEn/I+kPJQ1Kek3SnIh4u62NVGF7i6S+iOj4BzBsnydpj6RHIuKsYtmdknZFxB3F/1EeHxF/3SW93S5pT6en8S5mK5o0fJpxSZdL+hN18NyV9HWV2nDeOnFlnylpU0Rsjoh9kh6XNLsDfXS9iFgjadeIxbMlLSueL1PlP5a2q9JbV4iI7RHxevF8t6SD04x39NyV9NUWnQj7yZK2Dvt9UN0133tIWm17re3+TjcziokRsb14/qGkiZ1sZhQ1p/FupxHTjHfNuatn+vNG8Qbdl82KiLMlXSLphuLlaleKyt9g3TR2OqZpvNtllGnGf6WT567e6c8b1Ymwb5M0edjvpxTLukJEbCt+7pC0Ut03FfVHB2fQLX7u6HA/v9JN03iPNs24uuDcdXL6806E/TVJU21/zfZXJH1H0rMd6ONLbB9TvHEi28dIukjdNxX1s5LmFs/nSnqmg718QbdM411tmnF1+Nx1fPrziGj7Q9Klqrwj/wtJf9uJHqr09TuS/qt4vNXp3iQ9psrLuv9V5b2N6yWdKOllSe9KeknSCV3U23JJ6yW9qUqwJnWot1mqvER/U9K64nFpp89dSV9tOW98XBZIgjfogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJ/wOvsrBlxQrzGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 15\n",
    "plt.imshow(x_train[index],cmap='binary')\n",
    "plt.title('label {}'.format(y_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Dimension (60000, 28, 28)\n",
      "y_train Dimension (60000,)\n",
      "X_test Dimension (10000, 28, 28)\n",
      "y_test Dimension (10000,)\n",
      "Each Image HxW : 28x28\n"
     ]
    }
   ],
   "source": [
    "print('X_train Dimension {}'.format(x_train.shape))\n",
    "print('y_train Dimension {}'.format(y_train.shape)) # (val,1)\n",
    "print('X_test Dimension {}'.format(x_test.shape))\n",
    "print('y_test Dimension {}'.format(y_test.shape)) # (val,1)\n",
    "print('Each Image HxW : {}x{}'.format(x_train[0].shape[0],x_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding the Target Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encode = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encode # one-hot encoded 10 dimensional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y-train original - (60000,)\n",
      "Y-train One-Hot Encoding - (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Y-train original - {}'.format(y_train.shape))\n",
    "print('Y-train One-Hot Encoding - {}'.format(y_train_encode.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorising the input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape # initially we have 60000 samples of 28x28 images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorising essentially means converting 28x28 into 784 pixels vector i.e (60000,784)\n",
    "def vectorize(X):\n",
    "    samples = X.shape[0]\n",
    "    H = X.shape[1]\n",
    "    W = X.shape[2]\n",
    "    return samples, H, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vec Shape - (60000, 784)\n",
      "X_test_vec Shape - (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# X-train \n",
    "samples, H, W = vectorize(x_train)\n",
    "x_train_vec = x_train.reshape((samples,H*W))\n",
    "print('X_train_vec Shape - {}'.format(x_train_vec.shape))\n",
    "\n",
    "#X_test\n",
    "samples, H, W = vectorize(x_test)\n",
    "x_test_vec = x_test.reshape((samples,H*W))\n",
    "print('X_test_vec Shape - {}'.format(x_test_vec.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec_norm1 = x_train_vec/255\n",
    "X_test_vec_norm1 = x_test_vec/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = np.mean(x_train_vec)\n",
    "x_std = np.std(x_train_vec)\n",
    "\n",
    "epsilon = 1e-10\n",
    "\n",
    "x_train_norm2 = (x_train_vec - x_mean) / ( x_std + epsilon )\n",
    "X_test_norm2 = (x_test_vec - x_mean ) / ( x_std + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two normalised matrices are parsed through the networks to observe the differences\n",
    "norm_cache = {\"norm1\" : \"divide by 255 \", \"norm2\" : \"standard normalisation\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
